{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import re, os\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import DebertaTokenizer, DebertaModel, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len, target_list):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.title = list(df['text'])\n",
    "        self.targets = self.df[target_list].values\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.title)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.title[index])\n",
    "        title = \" \".join(title.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=True,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
    "            'targets': torch.FloatTensor(self.targets[index]),\n",
    "            'title': title\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "TEST_BATCH_SIZE = 32\n",
    "\n",
    "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base', truncation=True, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_unlabeled.csv')\n",
    "test_df['text'] = test_df['Title'] + ' ' + test_df['Abstract']\n",
    "\n",
    "pmids = test_df['PMID']\n",
    "\n",
    "test_df = test_df[['text', 'Label']]\n",
    "\n",
    "test_dataset = CustomDataset(test_df, tokenizer, MAX_LEN, ['Label'])\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size = TEST_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class  DebertaClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DebertaClass, self).__init__()\n",
    "        self.bert_model = DebertaModel.from_pretrained('microsoft/deberta-base')\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear = torch.nn.Linear(768, 1)\n",
    "    \n",
    "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
    "        output = self.bert_model(\n",
    "            input_ids, \n",
    "            attention_mask=attn_mask, \n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        cls_representation = output.last_hidden_state[:, 0]\n",
    "        output_dropout = self.dropout(cls_representation)\n",
    "        output = self.linear(output_dropout)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "model = DebertaClass()\n",
    "state_dict = torch.load(f\"./augdebertfiles/finetuned_deBERTa_epoch_2.model\", map_location=\"cuda\")\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "def get_predictions(model, data_loader):\n",
    "    \"\"\"\n",
    "    Outputs:\n",
    "      predictions - \n",
    "    \"\"\"\n",
    "    model = model.eval()\n",
    "    \n",
    "    titles = []\n",
    "    predictions = []\n",
    "    prediction_probs = []\n",
    "    target_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for data in data_loader:\n",
    "        title = data[\"title\"]\n",
    "        ids = data[\"input_ids\"].to(device, dtype = torch.long)\n",
    "        mask = data[\"attention_mask\"].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data[\"targets\"].to(device, dtype = torch.float)\n",
    "        \n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        \n",
    "        outputs = torch.sigmoid(outputs).detach().cpu()\n",
    "        custom_threshold = 0.46\n",
    "        preds = (outputs >= custom_threshold).float()\n",
    "        targets = targets.detach().cpu()\n",
    "\n",
    "        titles.extend(title)\n",
    "        predictions.extend(preds)\n",
    "        prediction_probs.extend(outputs)\n",
    "        target_values.extend(targets)\n",
    "    \n",
    "    predictions = torch.stack(predictions)\n",
    "    prediction_probs = torch.stack(prediction_probs)\n",
    "    target_values = torch.stack(target_values)\n",
    "    \n",
    "    return titles, predictions, prediction_probs, target_values\n",
    "\n",
    "\n",
    "\n",
    "titles, predictions, prediction_probs, target_values = get_predictions(model, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]] [935 162]\n"
     ]
    }
   ],
   "source": [
    "predictions = prediction_probs > 0.46\n",
    "\n",
    "predictions = predictions.int()\n",
    "# print the number of unique predictions\n",
    "unique, counts = np.unique(predictions, return_counts=True, axis=0)\n",
    "\n",
    "print(unique, counts)\n",
    "# unique, counts = np.unique(predictions, return_counts=True, axis=0)\n",
    "\n",
    "# print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester_df = pd.read_csv(\"test_unlabeled.csv\")\n",
    "\n",
    "# save the predictions to a csv file\n",
    "tester_df['label'] = predictions\n",
    "\n",
    "# convert the label to binary 0 or 1\n",
    "tester_df['label'] = tester_df['label'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "tester_df = tester_df[['PMID', 'label']]\n",
    "\n",
    "tester_df.to_csv(\"augdebertpreds/test_predictions-2-46.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    935\n",
       "1    162\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = pd.read_csv(\"augdebertpreds/test_predictions-2-46.csv\")\n",
    "\n",
    "arr['label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
